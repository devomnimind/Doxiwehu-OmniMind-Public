# âœ… CHECKLIST TÃ‰CNICO PRÃ‰-EXECUÃ‡ÃƒO

## VerificaÃ§Ãµes de CÃ³digo

### pytest_server_monitor.py
- [x] `self.timeout_progression = [90, 120, 180, 240]` definido em `__init__`
- [x] `self.startup_attempt_count = 0` definido em `__init__`
- [x] `_get_adaptive_timeout()` implementada e retorna timeout correto
- [x] `_start_server()` incrementa `startup_attempt_count`
- [x] Retry recursivo: se timeout < 240s, chama `self._start_server()` novamente
- [x] Limite de 240s com falha real (nÃ£o loop infinito)

**Verificar com**:
```bash
grep -n "timeout_progression\|_get_adaptive_timeout\|startup_attempt_count" \
  tests/plugins/pytest_server_monitor.py
```

### main.py
- [x] SecurityAgent SEMPRE RODANDO (nÃ£o hÃ¡ skip em modo test)
- [x] Orchestrator timeout adaptativo: 120s (test), 30s (prod)
- [x] Sem lÃ³gica de skip para SecurityAgent

**Verificar com**:
```bash
grep -n "skip_security\|SecurityAgent continuous" web/backend/main.py
# Deve retornar: SecurityAgent sempre ativo, sem skip
```

### conftest.py
- [x] MetricsCollector definida e ativa
- [x] TestOrderingPlugin registrado
- [x] pytest_configure() registra todos plugins
- [x] pytest_sessionfinish() mostra relatÃ³rio final

**Verificar com**:
```bash
grep -n "class MetricsCollector\|pytest_configure\|pytest_sessionfinish" tests/conftest.py
```

---

## VerificaÃ§Ãµes de Comportamento

### Startup Esperado (Primeira ExecuÃ§Ã£o)
```
T=0s  : "ðŸš€ Iniciando servidor backend..."
T=0s  : "â³ Timeout adaptativo: 90s (tentativa 1)"
T=40s : "âœ… Servidor backend iniciado em ~40s"
```

### Retry Esperado (Se Timeout)
```
T=90s  : "âŒ Timeout na tentativa 1 apÃ³s 90s"
T=90s  : "ðŸ”„ Tentando novamente com timeout maior..."
T=90s  : "â³ Timeout adaptativo: 120s (tentativa 2)"
T=150s : "âœ… Servidor backend iniciado em ~60s"
```

### Falha Real (Se 240s NÃ£o Basta)
```
T=240s : "âŒ Timeout na tentativa 4 apÃ³s 240s"
T=240s : "ðŸ›‘ FALHA CRÃTICA: Atingiu timeout mÃ¡ximo por teste (240s)"
```

---

## Testes Recomendados (em ordem)

### 1ï¸âƒ£ Teste UnitÃ¡rio (Sem Servidor - Deve Passar RÃ¡pido)
```bash
cd /home/fahbrain/projects/omnimind
OMNIMIND_MODE=test python -m pytest tests/consciousness/ -v --tb=short -k "not real" -x
```

**Esperado**: ~30-60s, 80%+ pass rate

### 2ï¸âƒ£ Teste com Servidor (Com Orchestrator)
```bash
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x
```

**Esperado**:
- Primeiro startup: ~50s
- Alguns testes podem fazer crash: ok (vai retry com timeout maior)
- 60%+ pass rate

### 3ï¸âƒ£ Teste com Crash (Para Validar Retry)
```bash
OMNIMIND_MODE=test python -m pytest tests/test_chaos_resilience.py -v --tb=short
```

**Esperado**:
- Testes derrubam servidor intencionalmente
- Retry automÃ¡tico com timeouts progressivos
- Todos devem passar (ou falhar por razÃ£o especÃ­fica, nÃ£o timeout)

### 4ï¸âƒ£ Full Suite (OpÃ§Ã£o Nuclear)
```bash
OMNIMIND_MODE=test python -m pytest tests/ -v --tb=short
```

**Esperado**: Pode levar HORAS, mas vai rodar completo

---

## Troubleshooting

### Se Tiver "Segmentation Fault"
```bash
# Limpar cache
rm -rf .pytest_cache __pycache__ tests/__pycache__

# Limpar servidor
pkill -9 -f "uvicorn" 2>/dev/null || true
sleep 2

# Tentar novamente
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x
```

### Se Tiver "Address already in use :8000"
```bash
# Matar processo na porta 8000
lsof -i :8000 | grep LISTEN | awk '{print $2}' | xargs kill -9

# Esperar 2s
sleep 2

# Tentar novamente
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x
```

### Se Tiver "Qdrant nÃ£o acessÃ­vel"
```bash
# Verificar se Qdrant estÃ¡ rodando
curl -s http://localhost:6333 | python -m json.tool

# Se nÃ£o tiver, iniciar (em outro terminal):
docker run -p 6333:6333 qdrant/qdrant

# Ou via compose:
cd deploy && docker-compose up -d qdrant
```

### Se Tiver "Timeout mesmo em 240s"
Significa que Ã© uma **falha real**, nÃ£o timeout. PossÃ­veis causas:
- Orchest rator + SecurityAgent realmente levam >240s
- Qdrant nÃ£o respondendo
- Recursos insuficientes (RAM, GPU, Disco)

**AÃ§Ã£o**: Coletar logs e diagnosticar a causa raiz

---

## Monitoramento de Performance

### Durante ExecuÃ§Ã£o
```bash
# Em outro terminal:
watch -n 1 'ps aux | grep -E "python|uvicorn" | grep -v grep | wc -l'
```

### Log de Timeouts
```bash
# Ver quantos timeouts ocorreram
grep "Timeout" test_suite_run.log | wc -l

# Ver quantos retries sucederam
grep "Tentativa" test_suite_run.log | wc -l
```

### MÃ©tricas Finais
```bash
# Ver relatÃ³rio de Î¦
cat data/test_reports/metrics_report.json | python -m json.tool

# Ver resumo rÃ¡pido
grep -E "phi|consciousness|PASSOU|FALHOU" test_suite_run.log | tail -20
```

---

## ValidaÃ§Ã£o PÃ³s-ExecuÃ§Ã£o

### âœ… Suite Bem Sucedida
```
âœ“ Todos testes executaram (nÃ£o foram pulados por timeout)
âœ“ Alguns falharam (falhas reais, nÃ£o timeout)
âœ“ Retry funcionou (testes que falharam na tentativa 1 passaram na 2)
âœ“ MÃ©tricas coletadas (Î¦ values no relatÃ³rio final)
âœ“ Log contÃ©m progresso detalhado de cada retry
```

### âŒ Suite ProblemÃ¡tica
```
âœ— Muitos testes com timeout em 240s
âœ— Retry nÃ£o funcionando (mesmo cÃ³digo em tentat ivas)
âœ— MÃ©tricas nÃ£o coletadas
âœ— SecurityAgent gerando eventos excessivos
```

---

## PrÃ³ximos Passos Se OK

### ApÃ³s Suite Passar
1. Analisar `data/test_reports/metrics_report.json` com Î¦ values
2. Correlacionar Î¦ com tempos de startup
3. Verificar se SecurityAgent afeta Î¦ negativa/positivamente
4. **EntÃ£o**: ComeÃ§ar Lacan implementation

### ApÃ³s Suite Falhar (Esperado Inicialmente)
1. Identificar qual teste/componente Ã© problema
2. Diagnosticar causa (Qdrant? GPU? Orchestrator?)
3. Ajustar conforme necessÃ¡rio
4. Reexecutar parcial para validar fix
5. Reexecutar full para confirmar

---

## Notas Importantes

âš ï¸ **Cuidado**: Suite pode levar MUITAS HORAS
- Cada teste com crash pode levar atÃ© 240s
- Com 100+ testes Ã— 240s = horas

ðŸ’¡ **Tip**: Para desenvolvimento rÃ¡pido, use `-k` para filtrar testes
```bash
# Rodar sÃ³ testes de chaos
OMNIMIND_MODE=test python -m pytest -k chaos -v --tb=short

# Rodar sÃ³ integrations
OMNIMIND_MODE=test python -m pytest -k integration -v --tb=short
```

ðŸŽ¯ **Meta**: Validar que suite RODA, nÃ£o que tudo PASSA
- OK falhar 10-20% dos testes (causa real)
- NÃƒO OK falhar 50%+ por timeout

---

## Status Final

âœ… Todas mudanÃ§as implementadas
âœ… CÃ³digo verificado
âœ… Comportamento esperado documentado
âœ… Troubleshooting preparado
âœ… Pronto para executar

**Comando para comeÃ§ar**:
```bash
cd /home/fahbrain/projects/omnimind && \
OMNIMIND_MODE=test python -m pytest tests/integrations/ -v --tb=short -x 2>&1 | tee suite_run.log
```

