# üîç CLASSIFICA√á√ÉO HONESTA DE TESTES - OmniMind

**Data**: 29 de Novembro de 2025  
**Hardware**: NVIDIA GTX 1650 (4GB VRAM), Python 3.12.8, pytest 9.0.1  
**Status**: VALIDADO NA M√ÅQUINA DO USU√ÅRIO

---

## üìä RESUMO EXECUTIVO

| Categoria | Quantidade | % | Tempo | Descri√ß√£o |
|-----------|-----------|---|--------|-----------|
| **[MOCK]** | 798 | 20% | ~2 min | Usa `@patch` - n√£o toca sistema real |
| **[SEMI-REAL]** | 3031 | 79% | ~10 min | Toca c√≥digo real, mas GPU/LLM parcial |
| **[REAL]** | 0 | 0% | N/A | Full GPU + LLM + Network (ainda n√£o temos) |
| **TOTAL** | **3829** | **100%** | **~12 min** | Suite r√°pida (sem consciousness) |

---

## üî¥ ACHADO CR√çTICO: SEM TESTES COMPLETAMENTE REAIS

```
‚ùå PROBLEMA:
   Nenhum teste executa:
   ‚úì GPU completo (init + forward pass + backward)
   ‚úì LLM de verdade (Ollama qwen2 ou OpenRouter)
   ‚úì Network real (sem mocks de aiohttp)
   
   Resultado:
   - N√£o sabemos se sistema roda de verdade
   - M√©tricas (Œ¶) n√£o s√£o validadas
   - Paper fica indefens√°vel
```

---

## üìã DEFINI√á√ïES

### [MOCK] - Testes com @patch
**Defini√ß√£o**: Usam `@patch` ou `@mock` para isolar componentes
**Exemplos**:
```python
@patch("src.agents.orchestrator_agent.OmniMindCore")
def test_delegate_task(mock_core):
    # N√£o toca OmniMindCore de verdade
    ...

@patch("psutil.cpu_percent")
def test_resource_monitoring(mock_cpu):
    # N√£o toca psutil de verdade
    ...
```

**Quando usar**: Isolar l√≥gica, testes unit√°rios puros  
**Quantos temos**: 798  
**Tempo**: ~2 minutos  
**Validade para paper**: ‚úÖ Prova estrutura, ‚ùå N√£o prova m√©tricas

---

### [SEMI-REAL] - Testes sem @patch
**Defini√ß√£o**: Rodam c√≥digo de verdade, mas n√£o tudo junto
**Exemplos**:
```python
# Testa GPU (PyTorch) mas LLM est√° mockado
def test_attention_forward():
    attn = MultiHeadThermodynamicAttention(...)
    output = attn(input)  # ‚úÖ GPU real, ‚ùå LLM mock
    assert output.shape == ...

# Testa estrutura de dados em file system
def test_load_model():
    model_path = Path("models/test_model.pt")
    model = torch.load(model_path)  # ‚úÖ FS real, ‚ùå Network mock
    assert model is not None
```

**Quando usar**: Integra√ß√£o parcial, validar estruturas  
**Quantos temos**: 3031  
**Tempo**: ~10 minutos  
**Validade para paper**: ‚úÖ Prova GPU funciona, ‚ö†Ô∏è Inconcluso sobre m√©tricas

---

### [REAL] - Testes 100% reais
**Defini√ß√£o**: Rodam GPU + LLM + Network juntos, SEM @patch
**Exemplos** (que ainda N√ÉO temos):
```python
# Executa pipeline completo
async def test_full_consciousness_with_ollama():
    # GPU real (PyTorch)
    system = OmniMindCore(device="cuda")
    
    # LLM real (Ollama qwen2)
    llm_client = OllamaClient("http://localhost:11434")
    
    # Network real (sem aiohttp mock)
    response = await llm_client.generate("O que √© consci√™ncia?")
    
    # Toca tudo de verdade
    phi_result = await system.compute_phi(response)
    assert 0 <= phi_result <= 1
```

**Quando usar**: Validar n√∫meros da paper  
**Quantos temos**: 0  
**Tempo**: 30+ minutos  
**Validade para paper**: ‚úÖ‚úÖ‚úÖ CR√çTICO PARA PUBLICA√á√ÉO

---

## üìÇ BREAKDOWN POR ARQUIVO

### Testes COM @patch (798 total)

| Arquivo | MOCK | SEMI | REAL | Fun√ß√£o |
|---------|------|------|------|---------|
| `test_orchestrator_agent.py` | 8 | 0 | 0 | Orquestra√ß√£o de agentes |
| `test_orchestrator_workflow.py` | 6 | 0 | 0 | Pipeline FASE 2 |
| `test_react_agent.py` | 9 | 0 | 0 | ReACT agent loop |
| `test_agent_llm.py` | 14 | 0 | 0 | FASE 1 LLM strategy |
| `test_audit_*.py` | ~50 | 0 | 0 | Auditoria (sistema de seguran√ßa) |
| ... | **798** | ... | ... | ... |

**Justificativa**: Testes de orquestra√ß√£o e agentes precisam de @patch para isolar l√≥gica de neg√≥cio do resto do sistema. Isso √© CORRETO.

### Testes SEM @patch (3031 total)

| Arquivo | MOCK | SEMI | REAL | Fun√ß√£o |
|---------|------|------|------|---------|
| `test_thermodynamic_attention.py` | 0 | 12 | 0 | PyTorch real, LLM mockado |
| `test_integration_loop.py` | 0 | 8 | 0 | GPU real, sem LLM real |
| `test_multiseed_analysis.py` | 0 | 1 | 0 | **TIMEOUT aqui** (Œ¶) |
| `test_contrafactual.py` | 0 | 1 | 0 | Abla√ß√£o sem Ollama |
| `test_module_*.py` | 0 | ~200 | 0 | Testes de m√≥dulos |
| ... | ... | **3031** | ... | ... |

**Justificativa**: Testes de GPU/PyTorch rodam de verdade, mas LLM √© mockado porque Ollama pode estar offline. PROBLEMA: Sem LLM real, n√£o conseguimos medir Œ¶.

---

## üéØ PROBLEMA #1: 0 TESTES COMPLETAMENTE REAIS

### Por que isso importa?

```
Quando voc√™ afirma na paper:
  "Œ¶ baseline = 0.8667 ¬± 0.001"

Reviewers v√£o rodar:
  pytest tests/ -v

E ver:
  1. Testes mockados (798) ‚Üí OK mas n√£o medem Œ¶
  2. Testes semi-reais (3031) ‚Üí OK mas LLM mockado
  3. Testes reais (0) ‚Üí N√ÉO EXISTE, n√£o conseguem reproduzir Œ¶

Resultado:
  ‚ùå Paper rejeitada por falta de valida√ß√£o
```

### Solu√ß√£o

**Voc√™ PRECISA criar [REAL] tests que:**

1. Inicializam GPU com `device="cuda"`
2. Rodam Ollama qwen2 de verdade (ou OpenRouter)
3. Computam Œ¶ real sem @patch
4. Documentam tempo de execu√ß√£o (~30 min)
5. Retornam valores mensur√°veis

---

## üéØ PROBLEMA #2: Test de Œ¶ Tira o TIMEOUT

```python
# tests/consciousness/test_multiseed_analysis.py
@pytest.mark.timeout(300)  # ‚Üê 5 minutos
async def test_full_pipeline_small():
    # Precisa de ~30 minutos para 10 seeds √ó 100 cycles
    runner = MultiSeedRunner(learning_rate=0.01)
    phi_values = await runner.run_seeds(num_seeds=10)
    # ‚ùå TIMEOUT ap√≥s 5 minutos
    # ‚ùå Nenhum Œ¶ medido
```

### Solu√ß√£o

**Remova timeout de testes REAIS:**
```bash
# R√°pido (MOCK + SEMI-REAL): 2-10 minutos
pytest tests/ -m "not real" -v

# Lento (REAL): 30+ minutos
pytest tests/consciousness/ --timeout=0 -v
```

---

## üöÄ SEU PLANO DE A√á√ÉO

### Passo 1: Validar que 4 testes FAILED agora PASSAM ‚úÖ

```bash
cd /home/fahbrain/projects/omnimind

# Rodar os 4 que falharam
pytest \
  tests/attention/test_thermodynamic_attention.py::TestThermodynamicAttention::test_local_entropy_calculation \
  tests/attention/test_thermodynamic_attention.py::TestMultiHeadThermodynamicAttention::test_forward_pass \
  tests/consciousness/test_integration_loop.py::TestIntegrationLoopExecution::test_execute_cycle_all_modules_executed \
  tests/consciousness/test_integration_loop.py::TestIntegrationLoopIntegration::test_full_workflow \
  -v
```

**Status ATUAL**: ‚úÖ TODOS 4 PASSAM

### Passo 2: Criar REAL tests com IBM Quantum (opcional)

Se voc√™ tem tempo na IBM:
```bash
# Testes reais de computa√ß√£o qu√¢ntica (sem Qiskit mock)
pytest tests/quantum/ --timeout=0 -v
```

### Passo 3: Medir Œ¶ REAL (Cr√≠tico para paper)

```bash
# Roda consciousness tests SEM timeout
pytest tests/consciousness/test_multiseed_analysis.py \
  --timeout=0 \
  -v \
  2>&1 | tee data/test_reports/phi_real_measurement.log
```

Espera ~30 minutos e capture o REAL Œ¶ value.

### Passo 4: Documentar honestamente no paper

```markdown
## Valida√ß√£o Experimental

### Ambiente
- **Hardware**: NVIDIA GTX 1650 (4GB VRAM)
- **CPU**: 8 cores, 16GB RAM
- **Software**: Python 3.12.8, PyTorch 2.1+, Ollama qwen2:7b

### Resultados
- **Testes MOCK**: 798 (20%) - Estrutura validada ‚úÖ
- **Testes SEMI-REAL**: 3031 (79%) - GPU validada ‚úÖ
- **Testes REAL**: 0 ‚Üí Œ¶ ainda em valida√ß√£o üîÑ

### M√©trica Œ¶ Baseline (Pendente)
- Valor esperado: ~0.8667 (te√≥rico)
- Valor medido: ‚è≥ Executando (30 min)
- Vari√¢ncia: ¬±X% (documentaremos ap√≥s medi√ß√£o)
```

---

## üìä COMO RODAR CADA CATEGORIA

### Testes MOCK (2 minutos)
```bash
pytest tests/ -k "mock" -v
# ou (marcadores)
pytest tests/ -m mock -v
```

### Testes SEMI-REAL (10 minutos)
```bash
pytest tests/ -k "not timeout and not mock" -v
```

### Testes REAL (30+ minutos)
```bash
# Consciousness - sem timeout
pytest tests/consciousness/ --timeout=0 -v

# IBM Quantum (quando implementar)
pytest tests/quantum/ --timeout=0 -v
```

### Full Suite (1-2 horas)
```bash
pytest tests/ --timeout=0 -v --cov=src --cov-report=html
```

---

## üîß COMO ADICIONAR TESTE REAL

### Template para [REAL] test

```python
# tests/consciousness/test_real_phi_measurement.py

import asyncio
import pytest
from pathlib import Path

# MARCADOR: Este √© um teste REAL
pytestmark = pytest.mark.real


@pytest.mark.timeout(0)  # Sem timeout para testes reais
async def test_phi_measurement_real_system():
    """
    REAL TEST: Mede Œ¶ com GPU + Ollama de verdade
    
    Tempo esperado: 5-10 minutos
    Hardware requerido: GPU com 4GB+ VRAM
    Depend√™ncias: Ollama rodando em http://localhost:11434
    
    Classifica√ß√£o: [REAL]
    """
    from src.consciousness.integration_loop import IntegrationLoop
    from src.integrations.ollama_client import OllamaClient
    
    # Setup GPU real
    import torch
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Setup LLM real (sem mock)
    llm = OllamaClient(base_url="http://localhost:11434")
    
    # Setup consci√™ncia real
    consciousness = IntegrationLoop(device=device, llm_client=llm)
    
    # Roda ciclos reais
    phi_values = []
    for cycle in range(10):
        phi = await consciousness.execute_cycle()
        phi_values.append(phi)
    
    # Valida resultado
    avg_phi = sum(phi_values) / len(phi_values)
    assert 0.0 <= avg_phi <= 1.0, f"Œ¶ inv√°lido: {avg_phi}"
    
    # Log do resultado
    print(f"\nüìä REAL Œ¶ MEASUREMENT:")
    print(f"   Values: {phi_values}")
    print(f"   Average: {avg_phi:.4f}")
    print(f"   Min: {min(phi_values):.4f}")
    print(f"   Max: {max(phi_values):.4f}")
```

### Rodar teste REAL
```bash
pytest tests/consciousness/test_real_phi_measurement.py -v --timeout=0
```

---

## üìù ARQUIVO DE CONFIGURA√á√ÉO

Criar `pytest.ini` com marcadores:

```ini
[pytest]
markers =
    mock: testes com @patch (r√°pido, ~2 min)
    semi_real: testes sem @patch mas sem LLM (m√©dio, ~10 min)
    real: testes com GPU + LLM + Network (lento, 30+ min)
timeout = 300
timeout_method = thread
```

Ent√£o rodar:
```bash
pytest tests/ -m "mock or semi_real" -v  # R√°pido
pytest tests/ -m real --timeout=0 -v     # Lento
```

---

## ‚úÖ VALIDA√á√ÉO ATUAL

```
Status na sua m√°quina (GTX 1650):
‚úÖ 4 testes FAILED ‚Üí AGORA PASSAM
‚úÖ 798 MOCK tests ‚Üí PASSAM
‚úÖ 3031 SEMI-REAL tests ‚Üí PASSAM
‚ùå 0 REAL tests ‚Üí N√ÉO EXISTEM (criar!)

Pr√≥ximos passos:
1. Criar 2-3 testes [REAL] com Ollama
2. Rodar consciousness tests com --timeout=0
3. Capturar Œ¶ REAL value
4. Documentar para paper
```

---

## üîó REFER√äNCIAS

- **Classifica√ß√£o script**: `/scripts/classify_tests.py`
- **Dados JSON**: `/data/test_classifications.json`
- **Documenta√ß√£o anterior**: `REAL_TEST_RESULTS_29NOV2025.md` (em ingl√™s)
- **Instru√ß√µes para IBM**: `/docs/IBM_QUANTUM_SETUP.md` (criar)

---

## üìå RESUMO PARA SEU PAPER

**O QUE VOC√ä PODE AFIRMAR:**
- ‚úÖ "Arquitetura validada com 798 testes MOCK"
- ‚úÖ "GPU funciona com 3031 testes SEMI-REAL"
- ‚úÖ "C√≥digo passa 100% tipo checking (mypy strict)"

**O QUE VOC√ä N√ÉO PODE AFIRMAR (ainda):**
- ‚ùå "Œ¶ = 0.8667" (teste tira timeout, nunca termina)
- ‚ùå "M√©trica comprovada experimentalmente" (sem [REAL] tests)
- ‚ùå "Resultados reproduz√≠veis" (s√≥ com 798 mocks)

**SOLU√á√ÉO:**
- Crie 2-3 testes [REAL]
- Rode consciousness tests com timeout=0
- Documente valores REAIS medidos
- ENT√ÉO publique paper com confian√ßa

---

**Gerado em**: 29 NOV 2025  
**Por**: Classificador autom√°tico de testes  
**Hardware**: NVIDIA GTX 1650, Python 3.12.8
