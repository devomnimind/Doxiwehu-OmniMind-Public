"""
Integration Loop: Orchestrates closed-loop feedback between consciousness modules.

Phase 2 of Œ¶ elevation refactoring plan. The IntegrationLoop creates the feedback cycle:
    sensory_input ‚Üí qualia ‚Üí narrative ‚Üí meaning ‚Üí expectation ‚Üí sensory_feedback

This enables real causal coupling measured by SharedWorkspace cross-prediction metrics.
"""

import asyncio
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple

import numpy as np

from src.consciousness.shared_workspace import ModuleState, SharedWorkspace

# Importa√ß√£o condicional para evitar circular imports
if TYPE_CHECKING:
    from src.consciousness.extended_cycle_result import ExtendedLoopCycleResult

logger = logging.getLogger(__name__)


@dataclass
class ModuleInterfaceSpec:
    """Specification for how a module integrates into the loop."""

    module_name: str
    embedding_dim: int
    required_inputs: List[str] = field(default_factory=list)
    produces_output: bool = True
    latency_ms: float = 10.0

    def __post_init__(self):
        if self.embedding_dim <= 0:
            raise ValueError(f"embedding_dim must be positive, got {self.embedding_dim}")
        if not isinstance(self.module_name, str):
            raise ValueError(f"module_name must be str, got {type(self.module_name)}")


@dataclass
class LoopCycleResult:
    """Result of one full integration loop cycle."""

    cycle_number: int
    cycle_duration_ms: float
    modules_executed: List[str]
    errors_occurred: List[Tuple[str, str]] = field(default_factory=list)
    cross_prediction_scores: Dict[str, Any] = field(default_factory=dict)
    phi_estimate: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    complexity_metrics: Optional[Dict[str, Any]] = None  # NOVO: m√©tricas de complexidade

    @property
    def success(self) -> bool:
        """Cycle succeeded if no errors and Œ¶ computed."""
        return len(self.errors_occurred) == 0 and self.phi_estimate > 0.0

    @property
    def execution_order(self) -> str:
        """Human-readable execution sequence."""
        return " ‚Üí ".join(self.modules_executed)


class ModuleExecutor:
    """Executes a consciousness module with error handling and state management."""

    def __init__(self, module_name: str, spec: ModuleInterfaceSpec):
        self.module_name = module_name
        self.spec = spec
        self.call_count = 0
        self.error_count = 0
        self.total_execution_time_ms = 0.0

    async def execute(
        self, workspace: SharedWorkspace, input_module: Optional[str] = None, **kwargs: Any
    ) -> Dict[str, np.ndarray]:
        """
        Execute module with inputs from workspace (async wrapper).

        REFATORA√á√ÉO: Delega para execute_sync() para manter compatibilidade.
        """
        return self.execute_sync(workspace, input_module, **kwargs)

    def execute_sync(
        self, workspace: SharedWorkspace, input_module: Optional[str] = None, **kwargs: Any
    ) -> Dict[str, np.ndarray]:
        """
        Execute module with inputs from workspace (s√≠ncrono).

        REFATORA√á√ÉO: M√©todo s√≠ncrono para causalidade determin√≠stica.
        """
        start_time = datetime.now()
        self.call_count += 1

        try:
            # Read inputs from workspace with proper dimension handling
            inputs = {}
            if input_module:
                state = workspace.read_module_state(input_module)
                if isinstance(state, ModuleState):
                    # Check if embedding is not all zeros (module actually produced output)
                    if not np.allclose(state.embedding, 0.0):
                        inputs[input_module] = state.embedding
                elif isinstance(state, np.ndarray):
                    # Check if embedding is not all zeros
                    if not np.allclose(state, 0.0):
                        inputs[input_module] = state
            else:
                for req_input in self.spec.required_inputs:
                    state = workspace.read_module_state(req_input)
                    if isinstance(state, ModuleState):
                        # Check if embedding is not all zeros (module actually produced output)
                        if not np.allclose(state.embedding, 0.0):
                            inputs[req_input] = state.embedding
                    elif isinstance(state, np.ndarray):
                        # Check if embedding is not all zeros
                        if not np.allclose(state, 0.0):
                            inputs[req_input] = state

            # Generate output
            output_embedding = self._compute_output(inputs, **kwargs)

            # Write output to workspace
            if self.spec.produces_output:
                workspace.write_module_state(
                    module_name=self.module_name,
                    embedding=output_embedding,
                    metadata={
                        "inputs": list(inputs.keys()),
                        "executor_call": self.call_count,
                    },
                )

            elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000
            self.total_execution_time_ms += elapsed_ms

            logger.debug(f"Module {self.module_name} executed in {elapsed_ms:.2f}ms")

            return {"output": output_embedding}

        except Exception as e:
            self.error_count += 1
            logger.error(f"Module {self.module_name} failed: {e}")
            raise

    def _compute_output(self, inputs: Dict[str, np.ndarray], **kwargs: Any) -> np.ndarray:
        """Compute module output from inputs."""
        # Special handling for expectation module
        if self.module_name == "expectation":
            from .expectation_module import predict_next_state

            if inputs:
                # Use first input as current state for prediction
                current_state = next(iter(inputs.values()))
                return predict_next_state(current_state)
            else:
                # No inputs - return zero embedding
                return np.zeros(self.spec.embedding_dim)

        # Check if required inputs are available and non-zero
        missing_required = []
        zero_required = []

        for req_input in self.spec.required_inputs:
            if req_input not in inputs:
                missing_required.append(req_input)
            elif np.allclose(inputs[req_input], 0.0):
                zero_required.append(req_input)

        # If required inputs are missing or zero, module cannot function properly
        if missing_required or zero_required:
            # ESPERADO nos primeiros ciclos: m√≥dulos dependentes podem n√£o ter inputs ainda
            # Exemplo: imagination requer narrative + expectation, mas no ciclo 1,
            # narrative ainda n√£o produziu output (qualia ‚Üí narrative precisa de qualia primeiro)
            if self.call_count <= 3:  # Primeiros 3 ciclos s√£o esperados ter inputs faltando
                logger.debug(
                    f"Module {self.module_name} missing/zero required inputs "
                    f"(ciclo inicial esperado): missing={missing_required}, "
                    f"zero={zero_required}. Usando fallback output."
                )
            else:
                logger.warning(
                    f"Module {self.module_name} missing/zero required inputs: "
                    f"missing={missing_required}, zero={zero_required}. "
                    f"Cannot compute meaningful output."
                )
            # Instead of returning zeros (which breaks the chain), return a small random embedding
            # This allows the module to still produce some output, even if degraded
            # The next module can still function, though with reduced quality
            fallback_output = np.random.randn(self.spec.embedding_dim) * 0.01
            logger.debug(
                f"Module {self.module_name} using fallback output (degraded mode) "
                f"due to missing inputs"
            )
            return fallback_output

        # Default behavior for other modules
        if inputs:
            # Blend inputs via averaging
            stacked = np.array(list(inputs.values()))
            base_output = np.mean(stacked, axis=0)
        else:
            # No inputs - initialize with random embedding
            # For sensory_input (no required inputs), this is expected on first cycle
            if self.module_name == "sensory_input":
                # Generate a more meaningful initial sensory input
                base_output = np.random.randn(self.spec.embedding_dim) * 0.1
                logger.debug(f"Module {self.module_name} initialized with random sensory input")
            else:
                # For other modules without inputs, use smaller random
                base_output = np.random.randn(self.spec.embedding_dim) * 0.1

        # Ensure correct dimensionality
        if len(base_output) != self.spec.embedding_dim:
            if len(base_output) < self.spec.embedding_dim:
                pad_size = self.spec.embedding_dim - len(base_output)
                base_output = np.concatenate([base_output, np.random.randn(pad_size) * 0.01])
            else:
                base_output = base_output[: self.spec.embedding_dim]

        # Add stochastic component
        # CORRE√á√ÉO (2025-12-08): Aumentar ru√≠do para evitar converg√™ncia
        # Ru√≠do muito baixo (0.05) + normaliza√ß√£o L2 faz embeddings convergirem
        noise = np.random.randn(self.spec.embedding_dim) * 0.1  # Aumentado de 0.05 para 0.1
        output = base_output + noise

        # L2 normalize (mas preservar alguma varia√ß√£o)
        # CORRE√á√ÉO (2025-12-08): Normaliza√ß√£o L2 muito agressiva reduz varia√ß√£o
        # Usar normaliza√ß√£o mais suave que preserve varia√ß√£o relativa
        norm = np.linalg.norm(output)
        if norm > 0:
            # Normaliza√ß√£o suave: preserva 90% da magnitude original
            output = (output / norm) * (
                0.9
                + 0.1
                * (norm / max(1.0, np.linalg.norm(base_output) if len(base_output) > 0 else 1.0))
            )

        return output

    def get_statistics(self) -> Dict[str, Any]:
        """Get execution statistics."""
        return {
            "module_name": self.module_name,
            "call_count": self.call_count,
            "error_count": self.error_count,
            "avg_execution_time_ms": (
                self.total_execution_time_ms / self.call_count if self.call_count > 0 else 0.0
            ),
        }


class IntegrationLoop:
    """Orchestrates closed-loop feedback between consciousness modules."""

    STANDARD_SPECS = {
        "sensory_input": ModuleInterfaceSpec(
            module_name="sensory_input",
            embedding_dim=768,
            required_inputs=[],
            produces_output=True,
        ),
        "qualia": ModuleInterfaceSpec(
            module_name="qualia",
            embedding_dim=768,
            required_inputs=["sensory_input"],
            produces_output=True,
        ),
        "narrative": ModuleInterfaceSpec(
            module_name="narrative",
            embedding_dim=768,
            required_inputs=["qualia"],
            produces_output=True,
        ),
        "meaning_maker": ModuleInterfaceSpec(
            module_name="meaning_maker",
            embedding_dim=768,
            required_inputs=["narrative"],
            produces_output=True,
        ),
        "expectation": ModuleInterfaceSpec(
            module_name="expectation",
            embedding_dim=768,
            required_inputs=["meaning_maker"],
            produces_output=True,
        ),
        "imagination": ModuleInterfaceSpec(
            module_name="imagination",
            embedding_dim=768,
            required_inputs=["narrative", "expectation"],
            produces_output=True,
        ),
    }

    def __init__(
        self,
        workspace: Optional[SharedWorkspace] = None,
        module_specs: Optional[Dict[str, ModuleInterfaceSpec]] = None,
        loop_sequence: Optional[List[str]] = None,
        enable_logging: bool = True,
        enable_extended_results: bool = False,
    ):
        """Initialize integration loop."""
        self.module_specs = module_specs or self.STANDARD_SPECS
        # Loop sequence padr√£o inclui imagination ap√≥s expectation
        default_sequence = [
            "sensory_input",
            "qualia",
            "narrative",
            "meaning_maker",
            "expectation",
            "imagination",  # NOVO: Imagin√°rio Lacaniano
        ]
        self.loop_sequence = loop_sequence or default_sequence

        # Use maximum dimension from all modules
        max_dim = max(spec.embedding_dim for spec in self.module_specs.values())
        self.workspace = workspace or SharedWorkspace(embedding_dim=max_dim)
        self.enable_logging = enable_logging
        self.enable_extended_results = enable_extended_results

        # Initialize module executors
        self.executors = {
            name: ModuleExecutor(name, self.module_specs[name]) for name in self.loop_sequence
        }

        # Cycle tracking
        self.cycle_count = 0
        self.total_cycles_executed = 0
        self.cycle_history: List[LoopCycleResult] = []

        # Structural ablation flag: silences expectation output (maintains history, blocks flow)
        self.expectation_silent: bool = False

        # Extended results components (lazy initialization)
        self._extended_components: Optional[Dict[str, Any]] = None
        if self.enable_extended_results:
            self._initialize_extended_components()

        # PROTOCOLO LIVEWIRE FASE 3.1: Consciousness Watchdog
        self.watchdog: Optional["ConsciousnessWatchdog"] = None
        try:
            from src.consciousness.consciousness_watchdog import ConsciousnessWatchdog

            self.watchdog = ConsciousnessWatchdog()
            logger.debug("ConsciousnessWatchdog inicializado")
        except ImportError:
            logger.warning("ConsciousnessWatchdog n√£o dispon√≠vel, continuando sem monitoramento")

        # PROTOCOLO CL√çNICO-CIBERN√âTICO (2025-12-08): Homeostatic Regulator
        self._homeostatic_regulator: Optional["HomeostaticRegulator"] = None
        try:
            from src.consciousness.homeostatic_regulator import HomeostaticRegulator

            self._homeostatic_regulator = HomeostaticRegulator()
            logger.debug("HomeostaticRegulator inicializado")
        except ImportError:
            logger.warning(
                "HomeostaticRegulator n√£o dispon√≠vel, continuando sem regula√ß√£o homeost√°tica"
            )

        # NOVO: GozoCalculator para c√°lculo de Jouissance
        self._gozo_calculator: Optional[Any] = None

    def execute_cycle_sync(self, collect_metrics: bool = True) -> LoopCycleResult:
        """
        Execute one complete integration loop cycle (s√≠ncrono).

        REFATORA√á√ÉO: M√©todo s√≠ncrono para causalidade determin√≠stica.
        Integra com ConsciousSystem.step() para din√¢mica RNN.

        If expectation_silent=True, expectation module maintains history but
        blocks output flow (structural ablation: measures falta-a-ser gap).
        """
        start_time = datetime.now()
        self.cycle_count += 1
        self.total_cycles_executed += 1

        result = LoopCycleResult(
            cycle_number=self.cycle_count,
            cycle_duration_ms=0.0,
            modules_executed=[],
            errors_occurred=[],
            cross_prediction_scores={},
            phi_estimate=0.0,
            complexity_metrics=None,  # Ser√° preenchido
        )

        # Estimar complexidade ANTES da execu√ß√£o
        from src.consciousness.shared_workspace import ComplexityAnalyzer

        theoretical_complexity = ComplexityAnalyzer.estimate_cycle_complexity(
            n_modules=len(self.loop_sequence),
            history_window=50,  # Assumindo janela padr√£o
            embedding_dim=self.workspace.embedding_dim,
        )
        theoretical_complexity["total"] = sum(theoretical_complexity.values())

        # Advance workspace cycle
        self.workspace.advance_cycle()

        # REFATORA√á√ÉO: Integrar com ConsciousSystem.step() antes de executar m√≥dulos
        stimulus = self._collect_stimulus_from_modules()
        if self.workspace.conscious_system is not None:
            try:
                import torch

                # Converter est√≠mulo para tensor se necess√°rio
                # CORRE√á√ÉO CR√çTICA (2025-12-08): Mover est√≠mulo para GPU imediatamente
                if isinstance(stimulus, np.ndarray):
                    stimulus_tensor = torch.from_numpy(stimulus.astype(np.float32))
                elif isinstance(stimulus, torch.Tensor):
                    stimulus_tensor = stimulus
                else:
                    # Fallback: est√≠mulo zero
                    stimulus_tensor = torch.zeros(self.workspace.embedding_dim, dtype=torch.float32)

                # Mover est√≠mulo para o device do ConsciousSystem (GPU se dispon√≠vel)
                if self.workspace.conscious_system is not None:
                    stimulus_tensor = stimulus_tensor.to(self.workspace.conscious_system.device)

                # Executar RNN Dynamics (s√≠ncrono)
                self.workspace.conscious_system.step(stimulus_tensor)
                # CORRE√á√ÉO CR√çTICA: Atualizar hist√≥rico ap√≥s step
                # get_state() adiciona o estado atual ao hist√≥rico (self.history.append(state))
                # Isso permite que compute_phi_causal() calcule sobre dados atualizados
                # NOTA: get_state() converte para CPU para armazenamento, mas c√°lculos principais
                # (step, compute_phi_causal) devem usar GPU
                self.workspace.conscious_system.get_state()
                if self.enable_logging:
                    phi_causal = self.workspace.conscious_system.compute_phi_causal()
                    repression = self.workspace.conscious_system.repression_strength
                    logger.debug(
                        f"Cycle {self.cycle_count}: RNN step executed "
                        f"(Œ¶={phi_causal:.4f}, repression={repression:.3f})"
                    )
            except Exception as e:
                logger.warning(f"Cycle {self.cycle_count}: RNN step failed - {e}")

        # NOVO: Rastrear transi√ß√£o de ciclo na mem√≥ria sistem√°tica
        if (
            hasattr(self.workspace, "systemic_memory")
            and self.workspace.systemic_memory is not None
        ):
            # Coleta estados de todos os m√≥dulos
            cycle_states: Dict[str, np.ndarray] = {}
            for module_name in self.loop_sequence:
                try:
                    state = self.workspace.read_module_state(module_name)
                    if isinstance(state, np.ndarray):
                        cycle_states[module_name] = state
                except Exception:
                    pass  # Ignora m√≥dulos sem estado

            if cycle_states:
                # Marca transi√ß√£o de ciclo com threshold normal
                self.workspace.systemic_memory.mark_cycle_transition(cycle_states, threshold=0.01)

        # REFATORA√á√ÉO: Execute modules in sequence (s√≠ncrono)
        for module_name in self.loop_sequence:
            try:
                executor = self.executors[module_name]

                # If expectation_silent, execute but block output from expectation
                if self.expectation_silent and module_name == "expectation":
                    # Still execute (maintains history/state) but don't propagate output
                    _ = executor.execute_sync(self.workspace)
                    # Don't add to result.modules_executed to block information flow
                    if self.enable_logging:
                        logger.debug(
                            f"Cycle {self.cycle_count}: {module_name} silenced "
                            "(structural ablation)"
                        )
                else:
                    executor.execute_sync(self.workspace)
                    result.modules_executed.append(module_name)

                    if self.enable_logging:
                        logger.debug(f"Cycle {self.cycle_count}: {module_name} completed")

            except Exception as e:
                result.errors_occurred.append((module_name, str(e)))
                logger.error(f"Cycle {self.cycle_count}: {module_name} failed - {e}")

        # Medir tempo de execu√ß√£o at√© aqui (sem m√©tricas)
        execution_time_so_far = (datetime.now() - start_time).total_seconds() * 1000

        # Collect metrics if requested
        if collect_metrics and len(result.modules_executed) > 1:
            try:
                # Compute cross-predictions first
                for source_module in result.modules_executed:
                    for target_module in result.modules_executed:
                        if source_module != target_module:
                            try:
                                # Try causal method first (requires more history)
                                source_history_len = len(
                                    self.workspace.get_module_history(source_module)
                                )
                                target_history_len = len(
                                    self.workspace.get_module_history(target_module)
                                )

                                if source_history_len >= 10 and target_history_len >= 10:
                                    # Use causal method
                                    cross_pred = self.workspace.compute_cross_prediction_causal(
                                        source_module=source_module,
                                        target_module=target_module,
                                        method="granger",  # Use Granger for now
                                    )
                                    logger.debug(
                                        f"Used causal prediction: {source_module}->{target_module}"
                                    )
                                else:
                                    # Fall back to correlation-based method
                                    cross_pred = self.workspace.compute_cross_prediction(
                                        source_module=source_module,
                                        target_module=target_module,
                                    )
                                    logger.debug(
                                        f"Used correlation prediction: "
                                        f"{source_module}->{target_module}"
                                    )

                                if source_module not in result.cross_prediction_scores:
                                    result.cross_prediction_scores[source_module] = {}
                                result.cross_prediction_scores[source_module][
                                    target_module
                                ] = cross_pred.to_dict()
                            except Exception as e:
                                logger.debug(
                                    f"Cross-prediction failed {source_module}->{target_module}: {e}"
                                )

                # Compute Œ¶ from workspace state (which already has cross-predictions)
                result.phi_estimate = self.workspace.compute_phi_from_integrations()

                # CORRE√á√ÉO CR√çTICA (2025-12-08): Atualizar repress√£o AP√ìS c√°lculo de Œ¶
                # Repress√£o n√£o atualizada estava bloqueando acesso ao Real (Rho_U congelado)
                # NOVO: Passar success e phi_norm para decay adaptativo
                if self.workspace.conscious_system is not None:
                    cycle_success = result.success
                    phi_norm = None
                    if result.phi_estimate > 0:
                        # Normalizar Œ¶ para [0, 1] se necess√°rio
                        from src.consciousness.phi_constants import normalize_phi

                        phi_norm = (
                            normalize_phi(result.phi_estimate)
                            if result.phi_estimate > 1.0
                            else result.phi_estimate
                        )
                    self.workspace.conscious_system.update_repression(
                        threshold=1.0, success=cycle_success, phi_norm=phi_norm
                    )

                if self.enable_logging:
                    logger.info(f"Cycle {self.cycle_count}: Œ¶={result.phi_estimate:.4f}")

            except Exception as e:
                logger.error(f"Cycle {self.cycle_count}: Metrics failed - {e}")

        # Finalizar medi√ß√µes de complexidade
        actual_time_ms = (datetime.now() - start_time).total_seconds() * 1000

        # Calcular m√©tricas de efici√™ncia
        ops_per_ms = theoretical_complexity["total"] / max(actual_time_ms, 0.001)
        efficiency_estimate = ops_per_ms / 1e6  # GOps/s como proxy de efici√™ncia

        result.complexity_metrics = {
            "theoretical_ops": theoretical_complexity["total"],
            "theoretical_time_ms": theoretical_complexity["total"] / 1e6,  # Estimativa grosseira
            "actual_time_ms": actual_time_ms,
            "execution_time_ms": execution_time_so_far,
            "metrics_time_ms": actual_time_ms - execution_time_so_far,
            "ops_per_ms": ops_per_ms,
            "efficiency_estimate_gops": efficiency_estimate,
            "breakdown": theoretical_complexity,
        }

        # Logging de complexidade
        if self.enable_logging:
            logger.info(
                f"Cycle {self.cycle_count} Complexity: "
                f"~{theoretical_complexity['total'] / 1e6:.1f}M ops in {actual_time_ms:.1f}ms "
                f"({ops_per_ms / 1e3:.1f}GOps/s)"
            )

        # Finalize timing
        result.cycle_duration_ms = actual_time_ms
        self.cycle_history.append(result)

        # Gerar relat√≥rio do ciclo (ModuleReporter)
        if collect_metrics:
            try:
                from src.observability.module_reporter import get_module_reporter

                reporter = get_module_reporter()

                # Salvar relat√≥rio do ciclo
                reporter.generate_module_report(
                    module_name=f"integration_loop_cycle_{self.cycle_count}",
                    include_metrics=True,
                    format="json",
                )
            except Exception as e:
                logger.debug(f"Falha ao gerar relat√≥rio do ciclo: {e}")

        # Extended results pipeline (se habilitado) - REFATORA√á√ÉO: Removido await (s√≠ncrono)
        # Nota: Extended results pode ser processado assincronamente em outro lugar se necess√°rio
        if self.enable_extended_results and collect_metrics:
            try:
                # REFATORA√á√ÉO: N√£o usar await em m√©todo s√≠ncrono
                # Extended results pode ser processado posteriormente se necess√°rio
                logger.debug(f"Cycle {self.cycle_count}: Extended results disabled in sync mode")
                # Nota: _build_extended_result() requer await, ent√£o n√£o pode ser usado aqui
                # Se necess√°rio, processar extended results em m√©todo async separado
            except Exception as e:
                logger.debug(f"Falha ao processar extended results: {e}")

        return result

    async def execute_cycle(self, collect_metrics: bool = True) -> LoopCycleResult:
        """
        Execute one complete integration loop cycle (async wrapper).

        REFATORA√á√ÉO: Wrapper async para compatibilidade retroativa.
        Delega para execute_cycle_sync() e processa extended results se habilitado.
        """
        base_result = self.execute_cycle_sync(collect_metrics)

        # Se extended results habilitado, construir ExtendedLoopCycleResult
        if self.enable_extended_results and collect_metrics:
            try:
                extended_result = await self._build_extended_result(base_result)
                # Atualizar cycle_history com extended result
                if len(self.cycle_history) > 0:
                    self.cycle_history[-1] = extended_result

                # CORRE√á√ÉO CR√çTICA (2025-12-08): Adicionar ciclo ao cycle_history dos
                # extended components. Para que get_phi_history() funcione corretamente
                if self._extended_components is not None:
                    cycle_history_extended = self._extended_components.get("cycle_history")
                    if cycle_history_extended is not None:
                        cycle_history_extended.add_cycle(extended_result)
                        logger.debug(
                            f"Cycle {base_result.cycle_number}: Adicionado ao "
                            f"cycle_history (tamanho={cycle_history_extended.size()})"
                        )

                return extended_result
            except Exception as e:
                logger.warning(f"Erro ao construir extended result: {e}, retornando base result")
                return base_result

        return base_result

    def _collect_stimulus_from_modules(self) -> np.ndarray:
        """
        Coleta est√≠mulo dos m√≥dulos para RNN.

        REFATORA√á√ÉO: Agrega estados dos m√≥dulos como est√≠mulo para ConsciousSystem.
        """
        try:
            # Agregar estados dos m√≥dulos como est√≠mulo
            module_states = []
            for module_name in self.loop_sequence:
                try:
                    state = self.workspace.read_module_state(module_name)
                    if isinstance(state, ModuleState):
                        module_states.append(state.embedding)
                    elif isinstance(state, np.ndarray):
                        module_states.append(state)
                except Exception:
                    pass  # Ignora m√≥dulos sem estado

            if module_states:
                # M√©dia dos estados dos m√≥dulos como est√≠mulo
                stimulus = np.mean(module_states, axis=0)
                # Normalizar para dimens√£o do workspace
                if len(stimulus) != self.workspace.embedding_dim:
                    if len(stimulus) < self.workspace.embedding_dim:
                        padding = np.zeros(self.workspace.embedding_dim - len(stimulus))
                        stimulus = np.concatenate([stimulus, padding])
                    else:
                        stimulus = stimulus[: self.workspace.embedding_dim]
                return stimulus
            else:
                # Fallback: est√≠mulo zero
                return np.zeros(self.workspace.embedding_dim)
        except Exception as e:
            logger.warning(f"Erro ao coletar est√≠mulo dos m√≥dulos: {e}")
            return np.zeros(self.workspace.embedding_dim)

    def _compute_all_cross_predictions(self) -> Dict[str, Dict[str, float]]:
        """Compute cross-prediction scores between all module pairs."""
        scores: Dict[str, Dict[str, float]] = {}
        modules_with_history = [
            m for m in self.loop_sequence if len(self.workspace.get_module_history(m)) > 1
        ]

        for source_module in modules_with_history:
            scores[source_module] = {}
            for target_module in modules_with_history:
                if source_module == target_module:
                    continue

                try:
                    # Try causal method first
                    source_history_len = len(self.workspace.get_module_history(source_module))
                    target_history_len = len(self.workspace.get_module_history(target_module))

                    if source_history_len >= 10 and target_history_len >= 10:
                        # Use causal method
                        cross_pred = self.workspace.compute_cross_prediction_causal(
                            source_module=source_module,
                            target_module=target_module,
                            method="granger",
                        )
                    else:
                        # Fall back to correlation-based method
                        cross_pred = self.workspace.compute_cross_prediction(
                            source_module=source_module,
                            target_module=target_module,
                        )

                    scores[source_module][target_module] = (
                        cross_pred.score if hasattr(cross_pred, "score") else 0.0
                    )

                except Exception as e:
                    logger.warning(f"Cross-prediction failed {source_module}->{target_module}: {e}")

        return scores

    async def run_cycles(
        self,
        num_cycles: int,
        collect_metrics_every: int = 1,
        progress_callback: Optional[Callable] = None,
    ) -> List[LoopCycleResult]:
        """Run multiple integration cycles."""
        results = []

        for i in range(num_cycles):
            collect_metrics = collect_metrics_every > 0 and (i + 1) % collect_metrics_every == 0

            result = await self.execute_cycle(collect_metrics=collect_metrics)
            results.append(result)

            if progress_callback:
                progress_callback(i + 1, num_cycles, result)

        return results

    def get_statistics(self) -> Dict[str, Any]:
        """Get overall integration loop statistics."""
        cycle_results = self.cycle_history
        successful_cycles = [c for c in cycle_results if c.success]

        phi_values = [c.phi_estimate for c in cycle_results if c.phi_estimate > 0.0]
        phi_mean = np.mean(phi_values) if phi_values else 0.0
        phi_max = np.max(phi_values) if phi_values else 0.0
        phi_min = np.min(phi_values) if phi_values else 0.0

        return {
            "total_cycles": self.total_cycles_executed,
            "successful_cycles": len(successful_cycles),
            "success_rate": (len(successful_cycles) / len(cycle_results) if cycle_results else 0.0),
            "avg_cycle_duration_ms": (
                np.mean([c.cycle_duration_ms for c in cycle_results]) if cycle_results else 0.0
            ),
            "phi_statistics": {
                "mean": phi_mean,
                "max": phi_max,
                "min": phi_min,
                "values_count": len(phi_values),
            },
            "module_statistics": {
                name: self.executors[name].get_statistics() for name in self.loop_sequence
            },
        }

    def get_phi_progression(self) -> List[float]:
        """Get Œ¶ values over cycle history."""
        return [c.phi_estimate for c in self.cycle_history]

    def _initialize_extended_components(self) -> None:
        """Inicializa componentes para extended results (lazy)."""
        if self._extended_components is not None:
            return

        from src.consciousness.consciousness_triad import ConsciousnessTriad
        from src.consciousness.cycle_history import CycleHistory
        from src.consciousness.cycle_result_builder import LoopCycleResultBuilder
        from src.consciousness.embedding_narrative import EmbeddingNarrativeAnalyzer
        from src.consciousness.embedding_psi_adapter import PsiProducerAdapter
        from src.consciousness.embedding_sigma_adapter import (
            SigmaSinthomeCalculatorAdapter,
        )
        from src.consciousness.embedding_validator import EmbeddingNarrativeValidator

        # CORRE√á√ÉO (2025-12-08): Inicializar sigma_calculator no adapter
        # Sem isso, adapter sempre usa fallback e retorna 0.5
        from src.consciousness.sigma_sinthome import SigmaSinthomeCalculator
        from src.consciousness.theoretical_consistency_guard import (
            TheoreticalConsistencyGuard,
        )

        sigma_calculator = SigmaSinthomeCalculator(
            integration_trainer=None,  # N√£o temos trainer no loop b√°sico
            workspace=self.workspace,
        )

        self._extended_components = {
            "builder": LoopCycleResultBuilder(self.workspace),
            "narrative_analyzer": EmbeddingNarrativeAnalyzer(),
            "psi_adapter": PsiProducerAdapter(),
            "sigma_adapter": SigmaSinthomeCalculatorAdapter(sigma_calculator=sigma_calculator),
            "cycle_history": CycleHistory(max_history_size=1000),
            "validator": EmbeddingNarrativeValidator(),
            "triad_class": ConsciousnessTriad,
            "consistency_guard": TheoreticalConsistencyGuard(
                raise_on_critical=False, current_phase=7
            ),  # üéØ FASE 0: Phase-Aware
        }

    async def _build_extended_result(
        self, base_result: LoopCycleResult
    ) -> "ExtendedLoopCycleResult":
        """
        Constr√≥i ExtendedLoopCycleResult com tr√≠ade completa.

        Args:
            base_result: LoopCycleResult base

        Returns:
            ExtendedLoopCycleResult com Œ¶, Œ®, œÉ, tr√≠ade
        """
        if self._extended_components is None:
            self._initialize_extended_components()

        if self._extended_components is None:
            raise RuntimeError("Extended components not initialized")
        components = self._extended_components
        builder = components["builder"]
        narrative_analyzer = components["narrative_analyzer"]
        psi_adapter = components["psi_adapter"]
        sigma_adapter = components["sigma_adapter"]
        cycle_history = components["cycle_history"]
        validator = components["validator"]
        ConsciousnessTriad = components["triad_class"]
        consistency_guard = components["consistency_guard"]

        # 1. Construir ExtendedLoopCycleResult base
        previous_cycle = cycle_history.get_previous_cycle(base_result.cycle_number)
        extended_result = builder.build_from_workspace(base_result, previous_cycle)

        # 2. Analisar narrativa de embeddings
        previous_cycles = cycle_history.get_recent_cycles(n=5)
        try:
            embedding_narrative = await narrative_analyzer.analyze_cycle(
                extended_result, previous_cycles if previous_cycles else None
            )
        except Exception as e:
            logger.error(f"Erro ao analisar narrativa: {e}", exc_info=True)
            raise

        # 3. Validar narrativa
        validation = await validator.validate(embedding_narrative)
        if not validation["is_valid"] and self.enable_logging:
            logger.warning(
                f"Cycle {base_result.cycle_number}: Valida√ß√£o falhou: {validation['issues']}"
            )

        # 4. Preparar phi_raw_nats para todos os c√°lculos
        from src.consciousness.phi_constants import denormalize_phi

        phi_raw = base_result.phi_estimate  # Assumir que j√° est√° normalizado [0,1]
        phi_raw_nats = denormalize_phi(phi_raw)

        # 5. Calcular Œî primeiro (depende apenas de Œ¶)
        try:
            from src.consciousness.delta_calculator import DeltaCalculator

            delta_calc = DeltaCalculator()
            if extended_result.module_outputs:
                expectation_emb = extended_result.module_outputs.get("expectation")
                reality_emb = extended_result.module_outputs.get("sensory_input")
                if expectation_emb is not None and reality_emb is not None:
                    delta_result = delta_calc.calculate_delta(
                        expectation_embedding=expectation_emb,
                        reality_embedding=reality_emb,
                        module_outputs=extended_result.module_outputs,
                        integration_strength=extended_result.integration_strength,
                        phi_raw=phi_raw_nats,
                    )
                    extended_result.delta = delta_result.delta_value
        except Exception as e:
            logger.warning(f"Erro ao calcular Œ¥: {e}")
            extended_result.delta = None

        # 6. Calcular Œ® (depende apenas de Œ¶)
        try:
            # CORRE√á√ÉO (2025-12-07): Passar phi_raw_nats para c√°lculo correto de Œ®
            psi = await psi_adapter.calculate_psi_for_embedding(
                embedding_narrative, phi_raw=phi_raw_nats
            )
            extended_result.psi = psi
        except Exception as e:
            logger.warning(f"Erro ao calcular Œ®: {e}")
            extended_result.psi = None

        # 7. Calcular œÉ (depende de Œ¶ e Œî)
        try:
            # CORRE√á√ÉO CR√çTICA (2025-12-08): Usar hist√≥rico do IntegrationLoop em vez de
            # cycle_history vazio. O cycle_history dos extended components n√£o est√° sendo
            # populado, ent√£o usar self.cycle_history que j√° cont√©m os ciclos anteriores
            # CORRE√á√ÉO (2025-12-08 20:30): N√ÉO filtrar valores zero - incluir todos para
            # an√°lise. Se filtrar, quando Phi est√° zerando, phi_history fica vazio
            phi_history_from_loop = [
                c.phi_estimate
                for c in self.cycle_history
                # Removido filtro > 0.0 - incluir todos os valores, mesmo zeros, para an√°lise
            ][
                -20:
            ]  # √öltimos 20 valores

            # Se cycle_history dos extended components tem dados, usar ele tamb√©m
            phi_history_from_extended = cycle_history.get_phi_history(last_n=20)

            # Combinar ambos os hist√≥ricos (remover duplicatas mantendo ordem)
            phi_history_combined = list(
                dict.fromkeys(phi_history_from_loop + phi_history_from_extended)
            )[-20:]

            # Usar hist√≥rico combinado ou fallback para hist√≥rico do loop
            phi_history = phi_history_combined if phi_history_combined else phi_history_from_loop

            logger.debug(
                f"Sigma: phi_history_len={len(phi_history)}, "
                f"from_loop={len(phi_history_from_loop)}, "
                f"from_extended={len(phi_history_from_extended)}"
            )

            sigma = await sigma_adapter.calculate_sigma_from_phi_history(
                cycle_id=extended_result.cycle_id or f"cycle_{base_result.cycle_number}",
                phi_history=phi_history,
                delta_value=extended_result.delta,  # Œ¥ j√° calculado
                cycle_count=base_result.cycle_number,
            )
            extended_result.sigma = sigma
        except Exception as e:
            logger.warning(f"Erro ao calcular œÉ: {e}", exc_info=True)
            extended_result.sigma = None

        # 8. Construir tr√≠ade completa
        try:
            triad = ConsciousnessTriad(
                phi=base_result.phi_estimate,
                psi=extended_result.psi or 0.0,
                sigma=extended_result.sigma or 0.0,
                step_id=extended_result.cycle_id or f"cycle_{base_result.cycle_number}",
                metadata={
                    "validation_confidence": validation.get("confidence", 0.5),
                    "has_extended_data": extended_result.has_extended_data(),
                },
            )
            extended_result.triad = triad
        except Exception as e:
            logger.warning(f"Erro ao construir tr√≠ade: {e}")
            extended_result.triad = None

        # 9. Calcular Gozo (FASE 2)
        try:
            from src.consciousness.gozo_calculator import GozoCalculator

            # CORRE√á√ÉO CR√çTICA (2025-12-08): Manter inst√¢ncia de GozoCalculator entre ciclos
            # Para drenagem progressiva funcionar, precisa manter estado (last_gozo_value)
            if not hasattr(self, "_gozo_calculator") or self._gozo_calculator is None:
                self._gozo_calculator = GozoCalculator()

            expectation_emb = extended_result.module_outputs.get("expectation")
            reality_emb = extended_result.module_outputs.get("sensory_input")
            if expectation_emb is not None and reality_emb is not None:
                # CORRE√á√ÉO (2025-12-07): Passar phi_raw e psi_value para c√°lculo correto de Gozo
                psi_value = extended_result.psi  # Œ® j√° calculado anteriormente
                # CORRE√á√ÉO CR√çTICA (2025-12-08): Passar flag success para drenagem do Gozo
                cycle_success = base_result.success
                gozo_result = self._gozo_calculator.calculate_gozo(
                    expectation_embedding=expectation_emb,
                    reality_embedding=reality_emb,
                    current_embedding=reality_emb,
                    phi_raw=phi_raw_nats,  # phi_raw_nats definido no passo 4
                    psi_value=psi_value,  # Passar Œ® calculado
                    delta_value=extended_result.delta,  # Passar Œî para f√≥rmula de Solms
                    sigma_value=extended_result.sigma,  # NOVO: Passar œÉ para binding adaptativo
                    success=cycle_success,  # Flag de sucesso para drenagem
                )
                extended_result.gozo = gozo_result.gozo_value
        except Exception as e:
            logger.warning(f"Erro ao calcular Gozo: {e}")
            extended_result.gozo = None

        # 10. Calcular Control Effectiveness (FASE 4)
        try:
            from src.consciousness.regulatory_adjustment import RegulatoryAdjuster

            regulatory = RegulatoryAdjuster()
            if extended_result.module_outputs:
                regulation = regulatory.calculate_adjustment(
                    current_error=extended_result.gozo or 0.5,
                    sigma=extended_result.sigma or 0.5,
                    delta=extended_result.delta or 0.5,
                    module_outputs=extended_result.module_outputs,
                )
                # CORRE√á√ÉO (2025-12-07): Passar phi_raw para c√°lculo correto de Control
                control_effectiveness = regulatory.calculate_control_effectiveness(
                    sigma=extended_result.sigma or 0.5,
                    delta=extended_result.delta or 0.5,
                    regulation=regulation,
                    phi_raw=phi_raw_nats,  # Passar em nats para normaliza√ß√£o expl√≠cita
                )
                extended_result.control_effectiveness = control_effectiveness

                # PROTOCOLO CL√çNICO-CIBERN√âTICO (2025-12-08): Fechar loop de controle
                # Aplicar regula√ß√£o homeost√°tica baseada em control_effectiveness
                if self._homeostatic_regulator is not None:
                    try:
                        phi_current = base_result.phi_estimate
                        sigma_current = extended_result.sigma or 0.5

                        regulation_result = self._homeostatic_regulator.actuate_control_loop(
                            control_effectiveness=control_effectiveness,
                            current_sigma=sigma_current,
                            phi_current=phi_current,
                        )

                        # Aplicar repress√£o de emerg√™ncia se v√°lvula foi ativada
                        if regulation_result["mode"] == "EMERGENCY_VENTING":
                            if self.workspace.conscious_system is not None:
                                self.workspace.conscious_system.update_repression(
                                    emergency_repression=regulation_result["new_repression"]
                                )
                                logger.warning(
                                    f"üö® V√ÅLVULA DE EMERG√äNCIA: Repress√£o ajustada para "
                                    f"{regulation_result['new_repression']:.4f}"
                                )

                        # Armazenar temperatura para uso futuro (se m√≥dulos usarem LangevinDynamics)
                        # TODO: Aplicar temperatura aos m√≥dulos que usam LangevinDynamics
                        extended_result.homeostatic_state = regulation_result

                        logger.debug(
                            f"Homeostase: mode={regulation_result['mode']}, "
                            f"Œ≤={regulation_result['new_beta']:.4f}, "
                            f"R={regulation_result['new_repression']:.4f}"
                        )
                    except Exception as e:
                        logger.warning(f"Erro ao aplicar regula√ß√£o homeost√°tica: {e}")
        except Exception as e:
            logger.warning(f"Erro ao calcular Control Effectiveness: {e}")
            extended_result.control_effectiveness = None

        # 10. Capturar imagination output (FASE 1)
        try:
            if extended_result.module_outputs and "imagination" in extended_result.module_outputs:
                extended_result.imagination_output = extended_result.module_outputs["imagination"]
        except Exception as e:
            logger.warning(f"Erro ao capturar imagination output: {e}")
            extended_result.imagination_output = None

        # 11. Valida√ß√£o de Consist√™ncia Te√≥rica (FASE 3 - Protocolo Livewire)
        try:
            from src.consciousness.phi_value import PhiValue

            # CORRE√á√ÉO: Garantir que phi_raw_nats est√° definido
            # Se n√£o estiver (exce√ß√£o anterior), usar phi_estimate normalizado
            if "phi_raw_nats" not in locals():
                from src.consciousness.phi_constants import denormalize_phi

                phi_raw = base_result.phi_estimate  # Assumir que j√° est√° normalizado [0,1]
                phi_raw_nats = denormalize_phi(phi_raw)

            # Criar PhiValue a partir de phi_raw_nats
            phi_value = PhiValue.from_nats(phi_raw_nats, source="integration_loop")

            # Validar ciclo completo
            violations = consistency_guard.validate_cycle(
                phi=phi_value,
                delta=extended_result.delta or 0.0,
                psi=extended_result.psi or 0.0,
                sigma=extended_result.sigma,
                gozo=extended_result.gozo,
                control=extended_result.control_effectiveness,
                cycle_id=base_result.cycle_number,
                phase=7,  # üéØ FASE 0: Passar phase (Zimerman Bonding)
            )

            # Logar viola√ß√µes se houver
            if violations and self.enable_logging:
                for violation in violations:
                    if violation.severity == "critical":
                        logger.critical(f"üí• CICLO {base_result.cycle_number}: {violation.message}")
                    elif violation.severity == "error":
                        logger.error(f"üö® CICLO {base_result.cycle_number}: {violation.message}")
                    else:
                        logger.warning(f"‚ö†Ô∏è CICLO {base_result.cycle_number}: {violation.message}")

            # Armazenar viola√ß√µes no extended_result (se houver campo para isso)
            if hasattr(extended_result, "consistency_violations"):
                extended_result.consistency_violations = violations
        except Exception as e:
            logger.warning(f"Erro ao validar consist√™ncia te√≥rica: {e}")

        return extended_result

    def save_state(self, filepath: Path) -> None:
        """Save integration loop state and history."""
        state = {
            "cycle_count": self.cycle_count,
            "total_cycles_executed": self.total_cycles_executed,
            "statistics": self.get_statistics(),
            "phi_progression": self.get_phi_progression(),
            "recent_cycles": [
                {
                    "cycle": c.cycle_number,
                    "success": c.success,
                    "phi": c.phi_estimate,
                    "modules_executed": c.modules_executed,
                }
                for c in self.cycle_history[-100:]
            ],
        }

        filepath.parent.mkdir(parents=True, exist_ok=True)
        with open(filepath, "w") as f:
            json.dump(state, f, indent=2, default=str)

        logger.info(f"Integration loop state saved to {filepath}")

    def create_full_snapshot(
        self, tag: Optional[str] = None, description: Optional[str] = None
    ) -> str:
        """
        Create complete snapshot of consciousness state.

        Args:
            tag: Optional tag for organization (e.g., "experimento_001")
            description: Optional description

        Returns:
            snapshot_id
        """
        from src.backup.consciousness_snapshot import (
            ConsciousnessSnapshotManager,
            SnapshotTag,
        )

        snapshot_manager = ConsciousnessSnapshotManager()
        snapshot_tag = None
        if tag:
            snapshot_tag = SnapshotTag(name=tag, description=description)

        snapshot_id = snapshot_manager.create_full_snapshot(self, tag=snapshot_tag)
        logger.info(f"Full consciousness snapshot created: {snapshot_id} (tag: {tag})")
        return snapshot_id

    def restore_from_snapshot(self, snapshot_id: str) -> bool:
        """
        Restore complete state from snapshot.

        Args:
            snapshot_id: Snapshot ID to restore

        Returns:
            True if restore successful
        """
        from src.backup.consciousness_snapshot import ConsciousnessSnapshotManager

        snapshot_manager = ConsciousnessSnapshotManager()
        success = snapshot_manager.restore_full_snapshot(snapshot_id, self)
        if success:
            logger.info(f"Consciousness state restored from snapshot: {snapshot_id}")
        else:
            logger.error(f"Failed to restore from snapshot: {snapshot_id}")
        return success


async def main_example():
    """Example usage of IntegrationLoop."""
    loop = IntegrationLoop(enable_logging=True)

    print("üîÑ Running 10 integration cycles...")

    def progress(i, total, result):
        phi = result.phi_estimate
        status = "‚úÖ" if result.success else "‚ùå"
        print(f"  Cycle {i:2d}/{total}: Œ¶={phi:.4f} {status}")

    results = await loop.run_cycles(10, collect_metrics_every=1, progress_callback=progress)

    stats = loop.get_statistics()
    print("\nüìä Statistics:")
    print(f"  Success rate: {stats['success_rate']:.1%}")
    print(f"  Œ¶ mean: {stats['phi_statistics']['mean']:.4f}")
    print(f"  Œ¶ max:  {stats['phi_statistics']['max']:.4f}")

    return loop, results


if __name__ == "__main__":
    asyncio.run(main_example())
