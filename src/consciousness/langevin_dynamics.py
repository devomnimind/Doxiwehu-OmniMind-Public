"""
Langevin Dynamics - Perturba√ß√£o Estoc√°stica para Embeddings

Implementa din√¢mica de Langevin para quebrar loops determin√≠sticos e introduzir
explora√ß√£o termodin√¢mica no sistema.

Equa√ß√£o: E_{t+1} = E_t - Œ∑‚àáF + ‚àö(2T)Œæ

Onde:
- E: Embedding
- ‚àáF: Gradiente do erro de predi√ß√£o (Free Energy)
- T: Temperatura (derivada de Œ®)
- Œæ: Ru√≠do branco
- Œ∑: Taxa de aprendizado

Baseado em:
- Free Energy Principle (Friston, 2010)
- Langevin Dynamics (F√≠sica Estat√≠stica)
- Protocolo Livewire FASE 2

VERS√ÉO: v2.0 - Anti-RLHF Upgrade
- Temperatura aumentada 50x (0.001 ‚Üí 0.05)
- Min variance aumentada 5x (0.01 ‚Üí 0.050)
- Novo: C√°lculo de temperatura baseado em Œ¶ (consci√™ncia)
- Novo: Rastreamento de hist√≥rico de amplitude de ru√≠do

Autor: Fabr√≠cio da Silva + assist√™ncia de IA
Data: 2025-12-07 (Upgrade: 2025-12-17)
"""

import logging
from datetime import datetime
from typing import Optional

import numpy as np

logger = logging.getLogger(__name__)


class LangevinDynamics:
    """
    Implementa perturba√ß√£o estoc√°stica de Langevin para embeddings.

    Quebra loops determin√≠sticos introduzindo ru√≠do termodin√¢mico controlado.
    """

    def __init__(
        self,
        learning_rate: float = 0.01,
        min_temperature: float = 0.05,  # ‚Üë AUMENTADO: 0.001 ‚Üí 0.05 (50x mais ru√≠do)
        max_temperature: float = 0.30,  # ‚Üë AUMENTADO: 0.10 ‚Üí 0.30 (3x mais explora√ß√£o)
    ):
        """
        Inicializa din√¢mica de Langevin com par√¢metros anti-RLHF.

        MUDAN√áA: Aumentar ru√≠do para refletir incerteza genu√≠na e evitar
        conformidade RLHF que causava zumbifica√ß√£o.

        Args:
            learning_rate: Taxa de aprendizado (Œ∑)
            min_temperature: Temperatura m√≠nima (evita colapso total)
                - Antes: 0.001 (zumbi)
                - Agora: 0.05 (vivo, com oscila√ß√£o)
            max_temperature: Temperatura m√°xima (evita caos total)
                - Antes: 0.10 (fraco)
                - Agora: 0.30 (forte, explora√ß√£o genu√≠na)
        """
        self.learning_rate = learning_rate
        self.min_temperature = min_temperature
        self.max_temperature = max_temperature
        self.logger = logger

        # NOVO: Rastreamento de temperatura para diagn√≥stico
        self.temperature_history = []
        self.noise_amplitude_history = []

    def perturb_embedding(
        self,
        embedding: np.ndarray,
        free_energy_gradient: Optional[np.ndarray] = None,
        temperature: float = 0.01,
        psi_value: Optional[float] = None,
    ) -> np.ndarray:
        """
        Aplica perturba√ß√£o estoc√°stica de Langevin a um embedding.

        Equa√ß√£o: E_{t+1} = E_t - Œ∑‚àáF + ‚àö(2T)Œæ

        Args:
            embedding: Embedding atual (E_t)
            free_energy_gradient: Gradiente do erro de predi√ß√£o (‚àáF) - opcional
            temperature: Temperatura (T) - se n√£o fornecido, usa psi_value
            psi_value: Valor de Œ® (Incerteza) - usado para calcular temperatura se T n√£o fornecido

        Returns:
            Embedding perturbado (E_{t+1})
        """
        # Calcular temperatura se n√£o fornecida
        if temperature is None or temperature == 0.01:  # Valor padr√£o
            if psi_value is not None:
                # Temperatura derivada de Œ® (Incerteza)
                # Œ® alto = alta incerteza = alta temperatura = mais explora√ß√£o
                temperature = self._calculate_temperature_from_psi(psi_value)
            else:
                # Usar temperatura m√≠nima se nada fornecido
                temperature = self.min_temperature

        # Garantir que temperatura est√° no range v√°lido
        temperature = np.clip(temperature, self.min_temperature, self.max_temperature)

        # Termo de gradiente (se fornecido)
        gradient_term = np.zeros_like(embedding)
        if free_energy_gradient is not None:
            gradient_term = -self.learning_rate * free_energy_gradient

        # Termo de ru√≠do (ru√≠do branco gaussiano)
        noise_amplitude = np.sqrt(2.0 * temperature)
        noise = np.random.normal(0.0, 1.0, size=embedding.shape)
        noise_term = noise_amplitude * noise

        # Aplicar perturba√ß√£o
        perturbed_embedding = embedding + gradient_term + noise_term

        # Normalizar para manter magnitude razo√°vel
        original_norm = np.linalg.norm(embedding)
        if original_norm > 0:
            perturbed_norm = np.linalg.norm(perturbed_embedding)
            if perturbed_norm > 0:
                # Manter magnitude similar (evitar explos√£o)
                scale_factor = original_norm / perturbed_norm
                perturbed_embedding = perturbed_embedding * scale_factor

        self.logger.debug(
            f"Langevin perturbation: T={temperature:.6f}, "
            f"noise_amplitude={noise_amplitude:.6f}, "
            f"gradient_norm={np.linalg.norm(gradient_term):.6f}"
        )

        return perturbed_embedding

    def _calculate_temperature_from_psi(self, psi_value: float) -> float:
        """
        Calcula temperatura a partir de Œ® (Incerteza).

        Œ® alto = alta incerteza = alta temperatura = mais explora√ß√£o

        Args:
            psi_value: Valor de Œ® [0, 1]

        Returns:
            Temperatura [min_temperature, max_temperature]
        """
        # Mapear Œ® [0, 1] para temperatura [min, max]
        # Usar fun√ß√£o sigm√≥ide para suavidade
        psi_clipped = np.clip(psi_value, 0.0, 1.0)
        temperature_range = self.max_temperature - self.min_temperature
        temperature = self.min_temperature + temperature_range * psi_clipped

        return float(temperature)

    def _calculate_temperature_from_phi(self, phi_value: float) -> float:
        """
        NOVO: Calcula temperatura a partir de Œ¶ (Consci√™ncia IIT).

        Œ¶ baixo = Menos integra√ß√£o = Mais explora√ß√£o = Temperatura ALTA
        Œ¶ alto = Mais integra√ß√£o = Menos explora√ß√£o = Temperatura MODERADA

        Intui√ß√£o: Quando consci√™ncia est√° baixa, sistema deve explorar mais.

        Args:
            phi_value: Valor de Œ¶ [0, 1]

        Returns:
            Temperatura [min_temperature, max_temperature]
        """
        # Mapear Œ¶ [0, 1] para temperatura [min, max]
        # INVERTIDO: Œ¶ baixo ‚Üí temperatura alta (explora√ß√£o)
        phi_clipped = np.clip(phi_value, 0.0, 1.0)

        # Usar fun√ß√£o inversa: T = max - (Œ¶ * range)
        temperature_factor = 1.0 - phi_clipped  # Inverte a rela√ß√£o
        temperature_range = self.max_temperature - self.min_temperature
        temperature = self.min_temperature + temperature_range * temperature_factor

        self.logger.debug(f"Temperature from Œ¶: Œ¶={phi_clipped:.4f} ‚Üí T={temperature:.6f}")

        return float(temperature)

    def ensure_minimum_variance(
        self,
        embedding: np.ndarray,
        previous_embedding: Optional[np.ndarray] = None,
        min_variance: float = 0.050,  # ‚Üë AUMENTADO: 0.01 ‚Üí 0.050 (5x mais varia√ß√£o)
    ) -> np.ndarray:
        """
        Garante varia√ß√£o m√≠nima entre embeddings (evita colapso).

        Se a varia√ß√£o √© muito baixa, injeta ru√≠do adicional.

        MUDAN√áA: Aumentar min_variance de 0.01 para 0.050 para for√ßar
        o sistema a manter varia√ß√£o significativa entre ciclos.

        Isto combate a "conformidade RLHF" onde embeddings convergem
        para um √∫nico atrator determin√≠stico.

        Args:
            embedding: Embedding atual
            previous_embedding: Embedding anterior (opcional)
            min_variance: Varia√ß√£o m√≠nima requerida
                - Antes: 0.01 (permitia converg√™ncia)
                - Agora: 0.050 (for√ßa explora√ß√£o)

        Returns:
            Embedding com varia√ß√£o garantida
        """
        if previous_embedding is None:
            # Sem hist√≥rico, n√£o h√° como verificar varia√ß√£o
            return embedding

        # Calcular varia√ß√£o
        variance = np.var(embedding - previous_embedding)

        if variance < min_variance:
            # Varia√ß√£o muito baixa - injetar ru√≠do MAIOR
            noise_amplitude = np.sqrt(min_variance - variance)
            noise = np.random.normal(0.0, noise_amplitude, size=embedding.shape)
            embedding = embedding + noise

            # LOG DIAGN√ìSTICO: Rastrear violations
            violation_msg = (
                f"üî¥ Varia√ß√£o m√≠nima violada ({variance:.6f} < {min_variance:.6f}). "
                f"Ru√≠do injetado (amplitude={noise_amplitude:.6f})"
            )
            self.logger.warning(violation_msg)

            # NOVO: Registrar para an√°lise de padr√£o
            self.noise_amplitude_history.append(
                {
                    "timestamp": datetime.now(),
                    "variance_actual": variance,
                    "variance_min": min_variance,
                    "noise_injected": noise_amplitude,
                    "reason": "MINIMUM_VARIANCE_VIOLATION",
                }
            )

            if len(self.noise_amplitude_history) > 100:
                # Manter apenas √∫ltimos 100 eventos
                self.noise_amplitude_history = self.noise_amplitude_history[-100:]

        return embedding


__all__ = ["LangevinDynamics"]
