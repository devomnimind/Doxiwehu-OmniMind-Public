# Integrations (Camada de Integra√ß√£o)

Este diret√≥rio cont√©m os adaptadores e clientes para servi√ßos externos e internos (LLMs, Vector DBs, APIs).

---

## ü¶ô Ollama Client (`ollama_client.py`)

Cliente ass√≠ncrono para interagir com o servidor de infer√™ncia local **Ollama**.
- **Fun√ß√£o**: Executar gera√ß√£o de texto localmente.
- **Novidade**: Integra√ß√£o nativa com **NPU Governance**. Toda gera√ß√£o dispara automaticamente o c√°lculo de $\Delta \Phi$ e Entropia.

### Configura√ß√£o de Modelos (.env)
O sistema agora utiliza uma arquitetura bicameral (R√°pido vs. Inteligente):

| Vari√°vel | Descri√ß√£o | Modelo Recomendado | Uso T√≠pico |
| :--- | :--- | :--- | :--- |
| `OMNIMIND_MODEL_FAST` | Modelo de baixa lat√™ncia | `qwen2:1.5b` | Respostas de chat, ferramentas r√°pidas. |
| `OMNIMIND_MODEL_SMART` | Modelo de alta capacidade | `phi3.5` | Sonhos, an√°lise profunda, s√≠ntese. |

---

## üîÄ LLM Router (`llm_router.py`)

Roteador central que decide qual modelo usar para cada tarefa.
- **Tier PREMIER/SMART**: Usa `OMNIMIND_MODEL_SMART` (Phi-3.5).
- **Tier FAST/BALANCED**: Usa `OMNIMIND_MODEL_FAST` (Qwen 2 1.5B).
- **Fallback**: Se o modelo local falhar ou n√£o estiver dispon√≠vel, o router pode degradar graciosamente ou tentar outro provedor (se configurado).

---

## üíæ Qdrant Integration (`qdrant_integration.py` / `qdrant_adapter.py`)

Adaptador para o banco de dados vetorial Qdrant.
- **Dimens√£o**: 384 (all-MiniLM-L6-v2).
- **Cole√ß√£o Principal**: `omnimind_memories` (Episodic/Sovereign Memory).
- **M√©todos**: Suporta `upsert`, `search` (via wrapper) e `query_points` (recomendado para novas vers√µes).
